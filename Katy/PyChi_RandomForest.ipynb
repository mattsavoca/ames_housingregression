{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyChi_RandomForest.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["OdJomIVCSHe0","ru1mBnjJTL5S"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WSqOaFRVR1dJ","colab_type":"text"},"source":["### Basic Setup"]},{"cell_type":"code","metadata":{"id":"jCCjycMbR0z8","colab_type":"code","colab":{}},"source":["#!pip install --upgrade Cython\n","#!pip install --upgrade git+https://github.com/statsmodels/statsmodels\n","  \n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import math\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z86A4201T9gJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"outputId":"dd5bb4a1-7b69-49de-fa5a-37205acdf75b","executionInfo":{"status":"error","timestamp":1558927921286,"user_tz":240,"elapsed":271,"user":{"displayName":"Katy Qian","photoUrl":"https://lh6.googleusercontent.com/-iuocLzlVXvA/AAAAAAAAAAI/AAAAAAAAA3A/jh4VdmKgT7I/s64/photo.jpg","userId":"17380243487654916020"}}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","\n","# This will prompt for authorization.\n","drive.mount('/content/drive')\n","\n","#if asked for authorization code, paste this code and press enter:\n","'''\n","4/UwFkrWBE8Eosyg0IayQntSJtqYl-W-fNawLpJuVJGXKMczzg7EAtEhw\n","'''\n","\n","train = pd.read_csv('/content/drive/My Drive/train.csv')\n","test = pd.read_csv('/content/drive/My Drive/test.csv')\n","pd.concat([train, test], axis = 0)\n","train.head()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-c4e2ed3d7bff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m '''\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/content/drive/My Drive/train.csv' does not exist: b'/content/drive/My Drive/train.csv'"]}]},{"cell_type":"markdown","metadata":{"id":"OdJomIVCSHe0","colab_type":"text"},"source":["### Helper Functions used for data manipulation"]},{"cell_type":"code","metadata":{"id":"oo_0TejESJJT","colab_type":"code","colab":{}},"source":["# function that adds a bunch of new fields\n","def beefup(ogdf):\n","    \n","    df = ogdf.copy()\n","    \n","    df['TotalBath'] = df['FullBath'] + df['HalfBath']\n","    df['BsmtTotBath'] = df['BsmtHalfBath'] + df['BsmtFullBath']\n","    \n","    df['RemodHome'] = (df['YearRemodAdd'] > df['YearBuilt']).apply(lambda x: 1 if x else 0)\n","    df['RemodGarage'] = (df['GarageYrBlt'] > df['YearBuilt']).apply(lambda x: 1 if x else 0)\n","    \n","    df['TotalPorchSF'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch']\n","    df['TotalPorchDeckSF'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch'] + df['WoodDeckSF']\n","    df['YardSF'] = df['LotArea'] - df['GrLivArea']\n","    \n","    df['Season'] = df['MoSold'].replace([12,1,2],\"Winter\").replace([3,4,5], \"Spring\").replace([6,7,8], \"Summer\").replace([9,10,11], \"Fall\")\n","    \n","    df['IndoorSF'] = df['1stFlrSF']+ df['2ndFlrSF'] + df['LowQualFinSF'] + df['TotalBsmtSF']\n","    df['AvgSFRm'] = (df['1stFlrSF'] + df['2ndFlrSF']) / df['TotRmsAbvGrd']\n","    \n","    df['MultiKitchen'] = df['KitchenAbvGr'].apply(lambda x: 1 if x > 1 else 0)\n","    df['MultiFireplace'] =  df['Fireplaces'].apply(lambda x: 1 if x > 1 else 0)\n","    df['ExtraRooms'] = df['TotRmsAbvGrd']- df['BedroomAbvGr'] - df['KitchenAbvGr']\n","    \n","    df['BsmtFinSF'] = df['BsmtFinSF1'] + df['BsmtFinSF2']\n","    df['BsmtFinYN'] = df['BsmtFinSF'].apply(lambda x: 1 if x > 0 else 0)\n","    \n","    df['PoolYN'] = df['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n","    df['FireplaceYN'] = df['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n","    df['FenceYN'] = df['Fence'].notnull().apply(lambda x: 1 if x else 0)\n","    \n","    df['ExteriorMixedYN'] = (df['Exterior1st'] != df['Exterior2nd']).apply(lambda x: 1 if x else 0)  \n","    \n","    return df\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Owny8XQSS99","colab_type":"code","colab":{}},"source":["#%% function fixes NAs by imputing 0, mean/mode or setting to \"Unknown\"/\"None\"\n","def nafix(df):    \n","    \n","    fixdf = df.copy()\n","    \n","    # specific oclumn drops\n","    fixdf = fixdf.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'Id'], axis = 1)\n","      \n","    # specific quants\n","    fixdf['GarageYrBlt'].fillna(fixdf['YearRemodAdd'], inplace = True)\n","    \n","    # specific cats\n","    catnonecol = ['MasVnrType', 'FireplaceQu',\n","                  'BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n","                  'GarageType','GarageFinish','GarageQual','GarageCond']\n","    \n","    for col in fixdf:\n","        if col in catnonecol:\n","            fixdf[col].fillna(\"None\", inplace = True)\n","    \n","    # Catch the rest of NAs & split into cat/quant\n","    cdf = fixdf.drop(fixdf._get_numeric_data().columns, axis = 1)\n","    t = np.sum(cdf.isnull(), axis = 0) \n","    cnacol = list(t[t>0].index.values)\n","    \n","    # If cat, then unknown. elseif quant, then 0.\n","    for col in fixdf:\n","        if col in cnacol:\n","            fixdf[col].fillna(\"Unknown\", inplace = True)\n","        else:\n","            fixdf[col].fillna(0, inplace = True)\n","            \n","    return fixdf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YNAV6d6CSVeA","colab_type":"code","colab":{}},"source":["#%% function that converts quant to category\n","def q_to_cat(ogdf, cols_to_convert):\n","    \n","    df = ogdf.copy()\n","    for col in df:\n","        if col in cols_to_convert:\n","            df[col] = df[col].astype(str)\n","    \n","    return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFizXn5ASXqA","colab_type":"code","colab":{}},"source":["#%% function does CATsuggested action\n","def optcat(ogdf, y, train_or_test):\n","    \n","    df = ogdf.copy()\n","    \n","    from CatAnalysis import catdf\n","    suggestdf = catdf(df, y, train_or_test)['suggest']\n","    \n","    quantifycols = list(suggestdf[suggestdf == \"quantify\"].index.values)\n","    ovacols = list(suggestdf[suggestdf == \"1vA\"].index.values)\n","    ignorecols = list(suggestdf[suggestdf == \"ignore\"].index.values)\n","    \n","    dumcols = list(suggestdf[suggestdf == 'dummify'].index.values)\n","    dumcols = dumcols + list(suggestdf[suggestdf == 'binary'].index.values)\n","    \n","    for col in df:\n","        if col in quantifycols:\n","            df[col] = df[col].fillna(0).replace('None', 0).replace('Po', 1).replace('Fa',2).replace('TA', 3).replace('Gd',4).replace('Ex',5)\n","        elif col in ovacols:\n","            df[col] = df[col].eq(df[col].mode()[0]).mul(1)\n","        elif col in ignorecols:\n","            df[col] = df.drop(col, axie = 1)\n","    \n","    df = pd.get_dummies(df, columns = dumcols, drop_first = True)\n","    \n","    return df"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZOfDmkr4SZhO","colab_type":"code","colab":{}},"source":["#%% Feature Manipulation GO!!!!\n","    \n","def thewholeshabang(ogdf, y, tot):\n","    temp = beefup(ogdf)\n","    temp = q_to_cat(temp, ['MSSubClass', 'OverallCond', 'MoSold'])\n","    temp = nafix(temp)\n","    temp = optcat(temp, y, tot)\n","    return temp\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HA2Q5VzmSb8f","colab_type":"code","colab":{}},"source":["### function to get metrics for CAT cols - fits 2xLR: dummy & one.v.all (one is top/mode)\n","def catdf(df,y,tot):\n","    \n","    df = df.drop(df._get_numeric_data().columns, axis = 1)\n","    \n","    dfdf = pd.DataFrame(columns = [\"unique\", \"set\", \n","                                   \"mode\", \"mode%\", \"NAs\",\n","                                   \"dummyLRscore\", \"ovaLRscore\", \n","                                   \"quantLRscore\", \"suggest\"])\n","    for col in df:\n","        \n","        temp = df.describe()\n","        quantcol = ['BsmtQual', 'BsmtCond', 'KitchenQual', 'ExterQual', 'ExterCond', \n","            'GarageQual', 'GarageCond', 'HeatingQC', 'FireplaceQu', 'PoolQC', 'OverallCond', 'OverallQual']\n","        \n","        xunique = temp.loc['unique', col]\n","        xset = df[col].unique()\n","        \n","        xmode = temp.loc['top', col]\n","        xmodep = round((temp.loc['freq', col] / df.shape[0]) *100, 2)\n","        xnas = df.shape[0] - temp.loc['count', col]\n","\n","        if tot == \"train\":\n","            from sklearn import linear_model\n","            xdummy = pd.get_dummies(df[col], drop_first=True)\n","            lrdummy = linear_model.LinearRegression()\n","            lrdummy.fit(xdummy, y)\n","            \n","            xova = df[col].eq(xmode).mul(1).values.reshape(-1, 1)\n","            lrova = linear_model.LinearRegression()\n","            lrova.fit(xova, y)\n","            \n","            xcorr = round(lrdummy.score(xdummy,y),4)\n","            xcorr2 = round(lrova.score(xova, y),4) \n","            xcorr3 = 0\n","            \n","            # only if in QUANTABLE columns\n","            if col in quantcol:\n","                if col in ['OverallCond', 'OverallQual']:\n","                    xquant = df[col].astype(int).values.reshape(-1, 1)\n","                else:\n","                    xquant = df[col].fillna(0).replace('None', 0).replace('Po', 1).replace('Fa',2).replace('TA', 3).replace('Gd',4).replace('Ex',5).values.reshape(-1, 1)\n","                lrquant = linear_model.LinearRegression()\n","                lrquant.fit(xquant, y)\n","                xcorr3 = round(lrquant.score(xquant, y),4)\n","            \n","            # determine action based on metrics\n","            if xnas >= df.shape[0]*.9:\n","                xaction = \"ignore\"\n","            elif xunique == 2:\n","                xaction = \"binary\"\n","            elif (xcorr2 + .01) > xcorr:\n","                xaction = \"1vA\"\n","            elif (xcorr3 + .01) > xcorr:\n","                xaction = \"quantify\"\n","            else:\n","                xaction = \"dummify\"\n","            \n","        else:\n","            xcorr = \"test\"\n","            xcorr2 = \"test\"\n","            xcorr3 = \"test\"\n","            xaction = \"test\"\n","    \n","        dfdf.loc[col] = [xunique, xset, xmode, xmodep, xnas, xcorr, xcorr2, xcorr3, xaction]\n","        \n","        # save results so can duplicate on test set later\n","        dfdf.to_csv(\"FeatureSuggestion.csv\", index = True)\n","    \n","    return dfdf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ErL2sMHSgeh","colab_type":"code","colab":{}},"source":["# function to create QUANTDF \n","def quantdf(df, y, tot):\n","    \n","    df = df._get_numeric_data()\n","    \n","    dfdf = pd.DataFrame(columns = [\"range\", \"mean\", \"std\", \n","                                   \"NAs\", \"non0\",\n","                                   \"outliers\", \"corr\", \"LRfit\"])\n","    for col in df:\n","        \n","        xrange = str(df[col].min()) + \" to \" + str(df[col].max())\n","        xmean = df[col].mean()\n","        xstd = df[col].std()\n","        \n","        xnas = df[col].isnull().sum()\n","        xnon0 = sum(df[col] != 0)\n","        \n","        xoutliers = len(detect_outlier(df[col]))\n","              \n","        if tot == \"train\":\n","            from sklearn import linear_model\n","            x = df[col].fillna(0).values.reshape(-1,1) # fillNA for LR only\n","            lr = linear_model.LinearRegression()\n","            lr.fit(x, y)\n","            xfit = round(lr.score(x,y),4)  \n","            xcorr = round(df[col].corr(y),5)\n","        else:\n","            xfit = \"na/test\"\n","            xcorr = \"na/test\"\n","    \n","        dfdf.loc[col] = [xrange, xmean, xstd,\n","                xnas, xnon0, \n","                xoutliers, xcorr, xfit]\n","    \n","    return dfdf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ru1mBnjJTL5S","colab_type":"text"},"source":["### Tree function"]},{"cell_type":"code","metadata":{"id":"7c3y3YsbTPg-","colab_type":"code","colab":{}},"source":["# function that takes a TRAIN DF, runs through random forest & optimizes, and returns key metrics\n","def treerun(df, logyn):\n","    \n","    import time\n","    import math\n","    stime = time.time()\n","    \n","    x = df.drop('SalePrice', axis = 1)\n","    y = np.log(df['SalePrice']) if logyn else df['SalePrice']\n","    cols = list(x.columns)\n","    \n","    # Tree Setup\n","    from sklearn import ensemble\n","    rf = ensemble.RandomForestRegressor()\n","    rf.set_params(random_state = 0, n_estimators = 100, max_features = round(math.sqrt(df.shape[1]),0)) #sqrt(numcol)\n","    \n","    # Test/Train split\n","    from sklearn.model_selection import train_test_split\n","    xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.2, random_state = 88)\n","         \n","    # CV to optimize max features & num trees\n","    from sklearn.model_selection import GridSearchCV\n","    grid = [{ \"max_features\": range(1, 25)}]\n","    grid_search = GridSearchCV(rf, grid, cv=5, n_jobs=-1)\n","    grid_search.fit(x, y)\n"," \n","    # Run again with BEST parameters\n","    bestrf = grid_search.best_estimator_\n","    bestscore = round(bestrf.score(xtest, ytest),4).mean()\n","    besterr = round(np.mean(abs(bestrf.predict(xtest) - ytest)),2)   \n","    \n","    # Rank importance\n","    rank = list(bestrf.feature_importances_)\n","    rank = [(x, round(rank, 2)) for x, rank in zip(cols, rank)]\n","    rank = sorted(rank, key = lambda x: x[1], reverse = True)\n","        \n","    # return score, mean abs error, top 5, time\n","    return bestscore, besterr, time.time() - stime, grid_search.best_params_['max_features'], rank[:5]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D47XU0OZTnoP","colab_type":"text"},"source":["### Trying different datasets with random forest and recording score in RESULTSDF"]},{"cell_type":"code","metadata":{"id":"BhH_9fyATiuN","colab_type":"code","colab":{}},"source":["# Create 3 datasets for model comparison\n","from FeatureAdd import nafix, thewholeshabang, beefup, q_to_cat\n","df_dumcat = train.copy() ; df_dumcat = nafix(df_dumcat); df_dumcat = pd.get_dummies(df_dumcat, drop_first = True)\n","df_nocat = train.copy() ; df_nocat = df_nocat._get_numeric_data().fillna(0) \n","df_optcat = train.copy() ; df_optcat = thewholeshabang(df_optcat, df_optcat['SalePrice'], \"train\")\n","df_qcat = train.copy() ; df_qcat = nafix(df_qcat)\n","\n","# Setup ResultsDf to store various model results\n","resultsdf = pd.DataFrame(columns = ['Score', 'Mean Abs Err', 'Comptime', 'MaxFeatures', 'Top5'])\n","\n","# Run with NOCAT (38f) - dropping all categories\n","xscore, xerr, xtime, xmaxf, xtop5 = treerun(df_nocat, logyn = False)\n","resultsdf.loc[\"Nocat\"] = [xscore, xerr, xtime, xmaxf, xtop5]\n","xscore, xerr, xtime, xmaxf, xtop5 = treerun(df_nocat, logyn = True)\n","resultsdf.loc[\"Nocat_log\"] = [xscore, xerr, xtime, xmaxf, xtop5]\n","\n","# Run with QCAT (46f) - C->Q for Poor-Excellent categories, and then dropping all categories\n","quantcol = ['BsmtQual', 'BsmtCond', 'KitchenQual', 'ExterQual', 'ExterCond', 'GarageQual', 'GarageCond', 'HeatingQC', 'FireplaceQu', 'PoolQC']\n","for col in df_qcat:\n","    if col in quantcol:\n","        df_qcat[col] = df_qcat[col].replace('None', 0).replace('Po', 1).replace('Fa',2).replace('TA', 3).replace('Gd',4).replace('Ex',5)\n","df_qcat = df_qcat._get_numeric_data()\n","\n","xscore, xerr, xtime, xmaxf, xtop5 = treerun(df_qcat, logyn = False)\n","resultsdf.loc[\"Qcat\"] = [xscore, xerr, xtime, xmaxf, xtop5]\n","xscore, xerr, xtime, xmaxf, xtop5 = treerun(df_qcat, logyn = True)\n","resultsdf.loc[\"Qcat_log\"] = [xscore, xerr, xtime, xmaxf, xtop5]\n","\n","# Run with DUMCAT (249f) - dummifying EVERYTHING\n","xscore, xerr, xtime, xmaxf, xtop5 = treerun(df_dumcat, logyn = False)\n","resultsdf.loc[\"Dumcat\"] = [xscore, xerr, xtime, xmaxf, xtop5]\n","xscore, xerr, xtime, xmaxf, xtop5 = treerun(df_dumcat, logyn = True)\n","resultsdf.loc[\"Dumcat_log\"] = [xscore, xerr, xtime, xmaxf, xtop5]\n","\n","# Run with OPTCAT (242f)- After hours of new feature adds, algorithms to decide what to do with each column, etc...\n","xscore, xerr, xtime, xmaxf, xtop5 = treerun(df_optcat, logyn = False)\n","resultsdf.loc[\"Optcat\"] = [xscore, xerr, xtime, xmaxf, xtop5]\n","xscore, xerr, xtime, xmaxf, xtop5 = treerun(df_optcat, logyn = True)\n","resultsdf.loc[\"Optcat_log\"] = [xscore, xerr, xtime, xmaxf, xtop5]\n","\n","# Save Resultsdf\n","resultsdf.to_csv('RandomForest_ModelCompare.csv', index=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_tLURyIWh5l","colab_type":"code","colab":{}},"source":["resultsdf"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"os28lT2oVdeU","colab_type":"text"},"source":["### Fitting TEST with best model above"]},{"cell_type":"code","metadata":{"id":"OOehj7iGVhq8","colab_type":"code","colab":{}},"source":["#%% Code to use model on test!\n","    \n","test = pd.read_csv(\"test.csv\")\n","df = test.copy(); df.set_index('Id')\n","\n","# Go through same feature engineering as train set\n","df = beefup(df)\n","df = nafix(df) \n","df = q_to_cat(df, ['MSSubClass', 'OverallCond', 'MoSold'])\n","\n","# Take the suggest list from previosly ran CatAnalysis for TRAIN set\n","suggestdf = pd.read_csv(\"FeatureSuggestion.csv\")\n","suggestdf = suggestdf.set_index('Unnamed: 0')['suggest']\n","\n","# split into different feature sets     \n","quantifycols = list(suggestdf[suggestdf == \"quantify\"].index.values)\n","ovacols = list(suggestdf[suggestdf == \"1vA\"].index.values)\n","ignorecols = list(suggestdf[suggestdf == \"ignore\"].index.values)\n","dumcols = list(suggestdf[suggestdf == 'dummify'].index.values)\n","dumcols = dumcols + list(suggestdf[suggestdf == 'binary'].index.values)\n","\n","# perform the suggested action\n","for col in df:\n","    if col in quantifycols:\n","        df[col] = df[col].fillna(0).replace('None', 0).replace('Po', 1).replace('Fa',2).replace('TA', 3).replace('Gd',4).replace('Ex',5)\n","    elif col in ovacols:\n","        df[col] = df[col].eq(df[col].mode()[0]).mul(1)\n","    elif col in ignorecols:\n","        df[col] = df.drop(col, axis = 1)\n","\n","df = pd.get_dummies(df, columns = dumcols, drop_first = True)\n","\n","# Now run transformed DF through tree\n","ytrain = np.log(df_optcat['SalePrice'])\n","xtrain = df_optcat.drop('SalePrice', axis = 1)\n","xtest = test\n","\n","# with just dummy all\n","#ytrain = df_dumcat['SalePrice']\n","#xtrain = df_dumcat.drop(['SalePrice', 'Id'], axis = 1)\n","#df = nafix(df)\n","#xtest = pd.get_dummies(df, drop_first = True)\n","\n","# Tree Setup\n","from sklearn import ensemble\n","rf = ensemble.RandomForestRegressor()\n","rf.set_params(random_state = 0, n_estimators = 100, max_features = 18) # as per results \n","rf.fit(xtrain, ytrain)\n","\n","# Predict!\n","submission = pd.Series(rf.predict(xtest))\n","submission = pd.concat([test['Id'], submission], axis = 1)\n","submission.columns = ['Id','SalePrice']\n","submission['SalePrice'] = round(np.exp(submission['SalePrice']),2)\n","\n","submission.to_csv(\"RF_Submission.csv\", index = False)\n","\n","# which columns are missing?\n","#diffcol = list(set(list(xtrain.columns)) - set(list(xtest.columns)))\n","#len(list(set(list(xtrain.columns)) - set(list(xtest.columns))))\n","#for i in diffcol[:10]:\n","#    xtest[i] = 0\n"],"execution_count":0,"outputs":[]}]}